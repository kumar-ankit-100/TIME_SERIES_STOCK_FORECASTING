{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac08d59-dc26-46fe-880d-fdbc3ebb66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------- Folder Setup -------------\n",
    "data_folder = r'C:\\Users\\jahna\\OneDrive\\Documents\\TIME_SERIES_STOCK_FORECASTING\\PREPROCESSING\\CLEAN_DATA_FINAL'\n",
    "traditional_output = r'C:\\Users\\jahna\\OneDrive\\Documents\\TIME_SERIES_STOCK_FORECASTING\\Time_Series_Models\\time_series_outputs'\n",
    "lstm_output = \n",
    "os.makedirs(traditional_output, exist_ok=True)\n",
    "os.makedirs(lstm_output, exist_ok=True)\n",
    "\n",
    "# ----------- Evaluation Metric -------------\n",
    "def evaluate(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return rmse, mae, mape\n",
    "\n",
    "# ----------- ARIMA Tuning -------------\n",
    "def tune_arima(train, test):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for p,d,q in itertools.product(range(0, 3), range(0,2), range(0,3)):\n",
    "        try:\n",
    "            model = ARIMA(train, order=(p,d,q)).fit()\n",
    "            pred = model.forecast(steps=len(test))\n",
    "            rmse = np.sqrt(mean_squared_error(test, pred))\n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, (p,d,q)\n",
    "        except:\n",
    "            continue\n",
    "    final_model = ARIMA(train, order=best_cfg).fit()\n",
    "    preds = final_model.forecast(steps=len(test))\n",
    "    return preds, best_cfg\n",
    "\n",
    "# ----------- SARIMA Tuning -------------\n",
    "def tune_sarima(train, test):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    for pdq in itertools.product(range(0,2), range(0,2), range(0,2)):\n",
    "        for seasonal_pdq in itertools.product(range(0,2), range(0,2), range(0,2)):\n",
    "            try:\n",
    "                model = SARIMAX(train, order=pdq, seasonal_order=seasonal_pdq + (12,)).fit(disp=False)\n",
    "                pred = model.forecast(len(test))\n",
    "                rmse = np.sqrt(mean_squared_error(test, pred))\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_cfg = rmse, (pdq, seasonal_pdq + (12,))\n",
    "            except:\n",
    "                continue\n",
    "    final_model = SARIMAX(train, order=best_cfg[0], seasonal_order=best_cfg[1]).fit(disp=False)\n",
    "    preds = final_model.forecast(len(test))\n",
    "    return preds, best_cfg\n",
    "\n",
    "# ----------- Prophet Tuning -------------\n",
    "def tune_prophet(df_prophet):\n",
    "    best_score = float(\"inf\")\n",
    "    best_params = None\n",
    "    best_preds = None\n",
    "    for cps in [0.01, 0.1, 0.5]:\n",
    "        for mode in ['additive', 'multiplicative']:\n",
    "            try:\n",
    "                model = Prophet(changepoint_prior_scale=cps, seasonality_mode=mode)\n",
    "                model.fit(df_prophet)\n",
    "                future = model.make_future_dataframe(periods=30)\n",
    "                forecast = model.predict(future)\n",
    "                y_pred = forecast.iloc[-30:]['yhat'].values\n",
    "                y_true = df_prophet['y'].values[-30:]\n",
    "                rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "                if rmse < best_score:\n",
    "                    best_score = rmse\n",
    "                    best_preds = y_pred\n",
    "                    best_params = {'cps': cps, 'mode': mode}\n",
    "            except:\n",
    "                continue\n",
    "    return best_preds, best_params\n",
    "\n",
    "# ----------- LSTM Model -------------\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def train_lstm(series):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(series.reshape(-1, 1))\n",
    "\n",
    "    seq_len = 30\n",
    "    X, y = create_sequences(scaled_data, seq_len)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(seq_len, 1)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model.fit(X_train, y_train, validation_split=0.2, epochs=20, batch_size=16, callbacks=[es], verbose=0)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    preds = scaler.inverse_transform(preds)\n",
    "    y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    return preds.flatten(), y_test_actual.flatten()\n",
    "\n",
    "# ----------- Process Each Stock File -------------\n",
    "traditional_records = []\n",
    "lstm_records = []\n",
    "\n",
    "for file in tqdm(os.listdir(data_folder)):\n",
    "    if not file.endswith(\".csv\"): continue\n",
    "    filepath = os.path.join(data_folder, file)\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    if 'Date' not in df.columns or 'Close' not in df.columns:\n",
    "        print(f\"Skipping {file}: Missing required columns\")\n",
    "        continue\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df = df.sort_values('Date')\n",
    "    series = df['Close'].values\n",
    "    stock_name = os.path.splitext(file)[0]\n",
    "\n",
    "    train_size = int(len(series) * 0.8)\n",
    "    train, test = series[:train_size], series[train_size:]\n",
    "\n",
    "    # ARIMA\n",
    "    try:\n",
    "        arima_pred, arima_params = tune_arima(train, test)\n",
    "        arima_rmse, arima_mae, arima_mape = evaluate(test, arima_pred)\n",
    "    except:\n",
    "        arima_rmse = arima_mae = arima_mape = None\n",
    "\n",
    "    # SARIMA\n",
    "    try:\n",
    "        sarima_pred, sarima_params = tune_sarima(train, test)\n",
    "        sarima_rmse, sarima_mae, sarima_mape = evaluate(test, sarima_pred)\n",
    "    except:\n",
    "        sarima_rmse = sarima_mae = sarima_mape = None\n",
    "\n",
    "    # Prophet\n",
    "    try:\n",
    "        df_prophet = df[['Date', 'Close']].rename(columns={'Date': 'ds', 'Close': 'y'})\n",
    "        prophet_pred, prophet_params = tune_prophet(df_prophet)\n",
    "        y_true = df_prophet['y'].values[-30:]\n",
    "        prophet_rmse, prophet_mae, prophet_mape = evaluate(y_true, prophet_pred)\n",
    "    except:\n",
    "        prophet_rmse = prophet_mae = prophet_mape = None\n",
    "\n",
    "    # Save traditional metrics\n",
    "    traditional_records.append({\n",
    "        'Stock': stock_name,\n",
    "        'ARIMA_RMSE': arima_rmse, 'ARIMA_MAE': arima_mae, 'ARIMA_MAPE': arima_mape,\n",
    "        'SARIMA_RMSE': sarima_rmse, 'SARIMA_MAE': sarima_mae, 'SARIMA_MAPE': sarima_mape,\n",
    "        'Prophet_RMSE': prophet_rmse, 'Prophet_MAE': prophet_mae, 'Prophet_MAPE': prophet_mape,\n",
    "    })\n",
    "\n",
    "    # LSTM\n",
    "    try:\n",
    "        lstm_pred, lstm_actual = train_lstm(series)\n",
    "        lstm_rmse, lstm_mae, lstm_mape = evaluate(lstm_actual, lstm_pred)\n",
    "    except:\n",
    "        lstm_rmse = lstm_mae = lstm_mape = None\n",
    "\n",
    "    lstm_records.append({\n",
    "        'Stock': stock_name,\n",
    "        'LSTM_RMSE': lstm_rmse,\n",
    "        'LSTM_MAE': lstm_mae,\n",
    "        'LSTM_MAPE': lstm_mape\n",
    "    })\n",
    "\n",
    "# ----------- Save Individual Results -------------\n",
    "pd.DataFrame(traditional_records).to_csv(f\"{traditional_output}/model_metrics_summary.csv\", index=False)\n",
    "pd.DataFrame(lstm_records).to_csv(f\"{lstm_output}/lstm_model_metrics.csv\", index=False)\n",
    "\n",
    "# ----------- Final Comparison -------------\n",
    "try:\n",
    "    traditional_df = pd.read_csv(f\"{traditional_output}/model_metrics_summary.csv\")\n",
    "except:\n",
    "    traditional_df = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    lstm_df = pd.read_csv(f\"{lstm_output}/lstm_model_metrics.csv\")\n",
    "except:\n",
    "    lstm_df = pd.DataFrame()\n",
    "\n",
    "combined_df = pd.merge(traditional_df, lstm_df, on='Stock', how='outer')\n",
    "\n",
    "def get_best_model(row):\n",
    "    scores = {\n",
    "        \"ARIMA\": row.get(\"ARIMA_RMSE\"),\n",
    "        \"SARIMA\": row.get(\"SARIMA_RMSE\"),\n",
    "        \"Prophet\": row.get(\"Prophet_RMSE\"),\n",
    "        \"LSTM\": row.get(\"LSTM_RMSE\"),\n",
    "    }\n",
    "    scores = {k: v for k, v in scores.items() if pd.notna(v)}\n",
    "    return min(scores, key=scores.get) if scores else None\n",
    "\n",
    "combined_df[\"Best_Model\"] = combined_df.apply(get_best_model, axis=1)\n",
    "combined_df.to_csv(\"final_model_comparison.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Final model comparison saved to: final_model_comparison.csv\")\n",
    "print(combined_df[[\"Stock\", \"Best_Model\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
